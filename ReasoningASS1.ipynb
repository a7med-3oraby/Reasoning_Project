{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Ahmed Adel Ahmed Oraby (20210550)\n",
        "\n",
        "#[1] import libraries\n",
        "import re\n",
        "from sympy.logic.boolalg import to_cnf\n",
        "\n",
        "#[2] Eliminate implication.\n",
        "def eliminate_implication(sentence):\n",
        "    \"\"\"\n",
        "    Function to eliminate implications in a logical sentence.\n",
        "    \"\"\"\n",
        "    # Remove the outer brackets if they exist\n",
        "    if sentence.startswith('(') and sentence.endswith(')'):\n",
        "        sentence = sentence[1:-1]\n",
        "\n",
        "    # Find the index of '=>'\n",
        "    imp_index = sentence.find('=>')\n",
        "\n",
        "    # Extract the antecedent and consequent parts\n",
        "    antecedent = sentence[:imp_index].strip()\n",
        "    consequent = sentence[imp_index + 2:].strip()\n",
        "\n",
        "    # Replace implication with equivalent form ~p | q\n",
        "    return f\"(¬{antecedent} ∨ {consequent})\"\n",
        "\n",
        "\n",
        "\n",
        "#[3] Demorgans_Law\n",
        "def move_negation_inward(sentence):\n",
        "    \"\"\"\n",
        "    Function to move negation inward using De Morgan's Law.\n",
        "    \"\"\"\n",
        "    # Apply De Morgan's Law: ~(p ∨ q) = (~p ∧ ~q) and ~(p ∧ q) = (~p ∨ ~q)\n",
        "    while \"¬(\" in sentence:\n",
        "        negation_index = sentence.find(\"¬(\")\n",
        "        closing_index = negation_index + 2\n",
        "        opened = 1\n",
        "        while opened != 0:\n",
        "            if sentence[closing_index] == '(':\n",
        "                opened += 1\n",
        "            elif sentence[closing_index] == ')':\n",
        "                opened -= 1\n",
        "            closing_index += 1\n",
        "\n",
        "        inner_expression = sentence[negation_index + 2:closing_index - 1]\n",
        "        negated_inner_expression = \"\"\n",
        "        for char in inner_expression:\n",
        "            if char == '∨':\n",
        "                negated_inner_expression += '∧'\n",
        "            elif char == '∧':\n",
        "                negated_inner_expression += '∨'\n",
        "            elif char.isalpha():\n",
        "                negated_inner_expression += '¬' + char\n",
        "\n",
        "        sentence = sentence[:negation_index] + negated_inner_expression + sentence[closing_index:]\n",
        "\n",
        "    return sentence\n",
        "\n",
        "\n",
        "\n",
        "#[3] Remove_double-not.\n",
        "def remove_double_not(sentence):\n",
        "    return sentence.replace(\"¬¬\", \"\")\n",
        "\n",
        "\n",
        "#[5] Standardize variable scope\n",
        "def Standardize_variable_scope(s):\n",
        "    vars = ['none','w', 'x', 'y', 'z']\n",
        "    new_string = \"\"\n",
        "    i = 0\n",
        "    for ch in s:\n",
        "        if ch == '∃' or ch == '∀':\n",
        "            i += 1\n",
        "        if ch in vars:\n",
        "            ch = vars[i]\n",
        "        new_string += ch\n",
        "    return new_string\n",
        "\n",
        "#[6] prenex form\n",
        "def prenex_form(s):\n",
        "    quantifiers = \"\"\n",
        "    new_string = \"\"\n",
        "    skip_next = False\n",
        "    for i, ch in enumerate(s):\n",
        "        if skip_next:\n",
        "            skip_next = False\n",
        "            continue\n",
        "        if ch in ['∃', '∀']:\n",
        "            quantifiers += ch + s[i + 1]\n",
        "            skip_next = True\n",
        "        else:\n",
        "            new_string += ch\n",
        "    return quantifiers + new_string\n",
        "\n",
        "def Skolemization(s):\n",
        "    result_string = \"\"\n",
        "    prefix_vars = []  # To store variables introduced by universal quantifiers (∀)\n",
        "    existential_vars = []  # To store variables that need to be replaced because they're introduced by existential quantifiers (∃)\n",
        "\n",
        "    # First pass: Identify and process quantifiers and variables\n",
        "    i = 0\n",
        "    while i < len(s):\n",
        "        if s[i] == '∀':\n",
        "            prefix_vars.append(s[i+1])  # Add variable after ∀ to the prefix list\n",
        "            result_string += s[i] + s[i+1]  # Keep ∀ and its variable in the result string\n",
        "            i += 2  # Skip next symbol (variable)\n",
        "        elif s[i] == '∃':\n",
        "            existential_vars.append(s[i+1])  # Add variable after ∃ to be replaced later\n",
        "            i += 2  # Skip ∃ and its variable, not adding them to result_string\n",
        "        else:\n",
        "            result_string += s[i]\n",
        "            i += 1\n",
        "\n",
        "    # Second pass: Replace existential variables with Skolem functions\n",
        "    final_result = \"\"\n",
        "    for ch in result_string:\n",
        "        if ch in existential_vars:\n",
        "            if prefix_vars:\n",
        "                skolem_function = f'F({\",\".join(prefix_vars)})'\n",
        "            else:\n",
        "                skolem_function = 'F()'\n",
        "            final_result += skolem_function\n",
        "        else:\n",
        "            final_result += ch\n",
        "\n",
        "    return final_result\n",
        "\n",
        "#[8] Eliminate universal quantifiers\n",
        "def Eliminate_universal_quantifiers(s):\n",
        "    pattern = r'∀[a-zA-Z]'\n",
        "    new_expression = re.sub(pattern, '', s)\n",
        "    return new_expression\n",
        "\n",
        "\n",
        "#[9] Convert to conjunctive normal form\n",
        "def Convert_to_conjunctive_normal_form(s):\n",
        "    new_string = eliminate_implication(s)\n",
        "    new_string = move_negation_inward(new_string)\n",
        "    new_string = remove_double_not(new_string)\n",
        "    return new_string\n",
        "\n",
        "#[10]Turn conjunctions into clauses in a set, and rename variables so that no clause shares the same variable name\n",
        "def Turn_conjunctions(s):\n",
        "    return s.split(\"^\")\n",
        "\n",
        "#[11] Rename variables in clauses so that each clause has a unique variable name\n",
        "def Rename_variables(lst):\n",
        "    vars = [\"w\", \"x\", \"y\", \"z\"]\n",
        "    i =0\n",
        "    for clause in range(len(lst)):\n",
        "        # lst[clause].replace(var in vars, vars[i])\n",
        "        cls =lst[clause]\n",
        "        for ch in cls:\n",
        "            if ch in vars:\n",
        "                cls = cls.replace(ch,vars[i])\n",
        "        lst[clause] = cls\n",
        "        i+=1\n",
        "    return lst\n",
        "\n",
        "\n",
        "#[12] Example\n",
        "\n",
        "logical_expression = \"∀x(P(x)→∃xQ(x))\"\n",
        "print(logical_expression)\n",
        "step1_result = eliminate_implication(logical_expression)\n",
        "print(\"After Eliminate_implication : \", step1_result)\n",
        "\n",
        "step2_result = move_negation_inward(step1_result)\n",
        "print(\"After Demorgan : \", step2_result)\n",
        "\n",
        "step3_result = remove_double_not(step2_result)\n",
        "print(\"After Remove_double_not : \", step3_result)\n",
        "\n",
        "step4_result = Standardize_variable_scope(logical_expression)\n",
        "print(\"After Standardize_variable_scope : \", step4_result)\n",
        "\n",
        "step5 = prenex_form(step4_result)\n",
        "print(\"before Skolemization : \", step5)\n",
        "\n",
        "step6 = Skolemization(step5)\n",
        "print(\"After Skolemization : \",step6)\n",
        "\n",
        "step7 = Eliminate_universal_quantifiers(step6)\n",
        "print(\"After Eliminate_universal_quantifiers : \", step7)\n",
        "\n",
        "step8 = Convert_to_conjunctive_normal_form(step7)\n",
        "print(\"After Convert_to_conjunctive_normal_form : \",step8)\n",
        "\n",
        "step9 = Turn_conjunctions(step8)\n",
        "print(\"After Turn_conjunctions : \",step9)\n",
        "\n",
        "step10 = Rename_variables(step9)\n",
        "print(\"After renaming : \",step10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EIgBQIQ076j",
        "outputId": "83e3beda-6fd0-413d-8d8b-9a8579bc08a4"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "∀x(P(x)→∃xQ(x))\n",
            "After Eliminate_implication :  (¬∀x(P(x)→∃xQ(x) ∨ x(P(x)→∃xQ(x)))\n",
            "After Demorgan :  (¬∀x(P(x)→∃xQ(x) ∨ x(P(x)→∃xQ(x)))\n",
            "After Remove_double_not :  (¬∀x(P(x)→∃xQ(x) ∨ x(P(x)→∃xQ(x)))\n",
            "After Standardize_variable_scope :  ∀w(P(w)→∃xQ(x))\n",
            "before Skolemization :  ∀w∃x(P(w)→Q(x))\n",
            "After Skolemization :  ∀w(P(w)→Q(F(w)))\n",
            "After Eliminate_universal_quantifiers :  (P(w)→Q(F(w)))\n",
            "After Convert_to_conjunctive_normal_form :  (¬P(w)→Q(F(w) ∨ (w)→Q(F(w)))\n",
            "After Turn_conjunctions :  ['(¬P(w)→Q(F(w) ∨ (w)→Q(F(w)))']\n",
            "After renaming :  ['(¬P(w)→Q(F(w) ∨ (w)→Q(F(w)))']\n"
          ]
        }
      ]
    }
  ]
}